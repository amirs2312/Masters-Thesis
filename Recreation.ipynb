{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpdflatex\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pdflatex\n",
    "import pylatexenc\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "import random\n",
    "from collections import deque\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import train\n",
    "importlib.reload(train)\n",
    "from train import train_DQN\n",
    "from train import train_quantum_dqn\n",
    "\n",
    "from qiskit import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit import transpile\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_aer import Aer\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime import SamplerV2 as Sampler\n",
    "from qiskit.quantum_info import Pauli\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "\n",
    "# Quick Check to see if my GPU is being detected\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else  \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using \", device)\n",
    "print(gym.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes used for Modelling\n",
    "\n",
    "- Setup the Classical Deep-Q-Network\n",
    "\n",
    "- Setup a Hybrid DQN that utilises the same structure as the above classical network, but with a 4-qubit VQC at the start.\n",
    "\n",
    "- The Hybrid DQN has two variations based on estimator and sampler QNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# A class deescribing a simple DQN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClassical_DQN\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m (\u001b[38;5;28mself\u001b[39m, state_size, action_size):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(Classical_DQN,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# A class deescribing a simple DQN\n",
    "class Classical_DQN(nn.Module):\n",
    "    def __init__ (self, state_size, action_size):\n",
    "        super(Classical_DQN,self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(state_size, 256)\n",
    "        self.layer_2 = nn.Linear(256,256)\n",
    "        self.output  = nn.Linear(256, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.layer_1(x))\n",
    "        x = nn.functional.relu(self.layer_2(x))\n",
    "        return self.output(x)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# A class describing a hybrid quantum-classical dqn\n",
    "class Hybrid_DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(Hybrid_DQN,self).__init__()\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.num_qubits = 4\n",
    "        self.quantum_layer     = self.create_quantum_layer_type1()\n",
    "        self.classical_layer_1 = nn.Linear(4, 256)\n",
    "        self.classical_layer_2 = nn.Linear(256, 256)\n",
    "        self.output_layer      = nn.Linear(256, action_size)\n",
    "\n",
    "\n",
    "    # Angle encoding for the cartpole state variables\n",
    "    def encode_cartpole_state(self, x):\n",
    "        \n",
    "        min_vals = torch.tensor([-4.8, -3.0, -0.418, -3.0]) # The reasonable minimum values of the state variables\n",
    "        max_vals = torch.tensor([4.8, 3.0, 0.418, 3.0]) # The reasonable maximum values of the state variables\n",
    "\n",
    "        theta_vals = (x - min_vals) / (max_vals - min_vals) * (2 * torch.pi) - torch.pi\n",
    "        return theta_vals\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.to(next(self.parameters()))\n",
    "        theta_vals = self.encode_cartpole_state(x) # Determine encoding parameter values\n",
    "\n",
    "        quantum_output = self.quantum_layer(theta_vals) # Encode the state variables in a quantum format\n",
    "\n",
    "        x = torch.relu(self.classical_layer_1(quantum_output))\n",
    "        x = torch.relu(self.classical_layer_2(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def create_quantum_layer_type1(self):\n",
    "\n",
    "        num_qubits = 4\n",
    "        vqc = QuantumCircuit(num_qubits)\n",
    "\n",
    "        # To transalte the state vector into a quantum representation\n",
    "        encoding_params = [Parameter(f'theta_{i}') for i in range(num_qubits)]\n",
    "        trainable_params = [Parameter(f'w_{i}') for i in range(num_qubits)]\n",
    "\n",
    "        # Encoding\n",
    "        for i, param in enumerate(encoding_params):\n",
    "            vqc.ry(param, i)\n",
    "\n",
    "        # Hadamard each qubit\n",
    "        for i in range(num_qubits):\n",
    "            vqc.h(i)\n",
    "\n",
    "        for i in range(3):\n",
    "            vqc.cx(i, i + 1)\n",
    "        vqc.cx(3, 0)\n",
    "\n",
    "        # The Actual VQC\n",
    "        for i, param in enumerate(trainable_params):\n",
    "            vqc.ry(param, i)\n",
    "\n",
    "\n",
    "        # An observable for each Z-value of each qubit. Effectively telling us what the qubits expectation is in terms of  |0> and |1>\n",
    "        observables = [\n",
    "        SparsePauliOp.from_list([(\"ZIII\", 1)]),\n",
    "        SparsePauliOp.from_list([(\"IZII\", 1)]),\n",
    "        SparsePauliOp.from_list([(\"IIZI\", 1)]),\n",
    "        SparsePauliOp.from_list([(\"IIIZ\", 1)])\n",
    "        ]\n",
    "\n",
    "        qnn = EstimatorQNN(\n",
    "            circuit=vqc,\n",
    "            input_params =encoding_params,\n",
    "            weight_params=trainable_params,\n",
    "            observables  = observables\n",
    "                    )\n",
    "        return TorchConnector(qnn)\n",
    "    \n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)  # FIFO queue to hold experiences\n",
    "\n",
    "    # Add an experience to the buffer\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    # Sample an experience from the buffer\n",
    "    def sample(self, batch_size):\n",
    "\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    # Return the currenlength of the buffer\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical_DQN(\n",
      "  (layer_1): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (layer_2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=2, bias=True)\n",
      ") \n",
      "\n",
      "True\n",
      "Hybrid_DQN(\n",
      "  (quantum_layer): TorchConnector()\n",
      "  (classical_layer_1): Linear(in_features=4, out_features=256, bias=True)\n",
      "  (classical_layer_2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (output_layer): Linear(in_features=256, out_features=2, bias=True)\n",
      ")\n",
      "Environment and models are set up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "\n",
    "# Creating live and target models\n",
    "live_model = Classical_DQN(state_size, action_size).to(device)\n",
    "\n",
    "target_model = Classical_DQN(state_size, action_size).to(device)\n",
    "target_model.load_state_dict(live_model.state_dict())\n",
    "target_model.eval()  \n",
    "\n",
    "print(live_model, \"\\n\")\n",
    "\n",
    "\n",
    "live_qmodel = Hybrid_DQN(state_size, action_size)\n",
    "print(hasattr(live_qmodel, 'encode_cartpole_state'))\n",
    "\n",
    "target_qmodel = Hybrid_DQN(state_size, action_size)\n",
    "target_qmodel.load_state_dict(live_qmodel.state_dict())\n",
    "target_qmodel.eval()  \n",
    "\n",
    "print(live_qmodel)\n",
    "\n",
    "\n",
    "print(\"Environment and models are set up.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning \n",
    "\n",
    "- Exactly what it sounds like.\n",
    "\n",
    "- Most parameters are taken from Evans work (Some of which he takes from other work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the training buffer for experience replay\n",
    "buffer_capacity = 4000\n",
    "replay_buffer = ReplayBuffer(buffer_capacity)\n",
    "\n",
    "\n",
    "# Optimisers for the classical and quantum networks\n",
    "optimizer = optim.Adam(live_model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizerq = optim.Adam(live_qmodel.parameters(), lr=0.001)\n",
    "criterionq = torch.nn.MSELoss()\n",
    "\n",
    "gamma = 0.98              # Discount factor for future rewards (Not specified) \n",
    "epsilon = 1.0             # Initial exploration rate (Specified)\n",
    "epsilon_decay = 0.99      # Decay rate for epsilon (Specfied)\n",
    "epsilon_min = 0.005       # Minimum exploration rate (Specified) \n",
    "batch_size = 128          # Number of experiences sampled per update (Specified)\n",
    "target_update_freq = 10   # Frequency to update the target network (Not specified)\n",
    "num_episodes = 300        # The number of episodes or epochs to train (Specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "- First cell is classical\n",
    "\n",
    "- Second cell is hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "y = train_DQN(env, epsilon, epsilon_decay, num_episodes, replay_buffer, batch_size, target_update_freq, epsilon_min, gamma, device, live_model, target_model, criterion, optimizer)\n",
    "\n",
    "#y = [1,2,3,4]\n",
    "filename = f\"Training/output_{os.getpid()}.txt\"\n",
    "np.savetxt(filename, y, fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saad\\Project\\train.py:123: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n",
      "c:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_quantum_dqn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_update_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_qmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_qmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizerq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#x = live_qmodel(torch.tensor([0.1,0.2,0.3,0.4]))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining/output_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mgetpid()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Saad\\Project\\train.py:173\u001b[0m, in \u001b[0;36mtrain_quantum_dqn\u001b[1;34m(env, epsilon, epsilon_decay, num_episodes, replay_buffer, batch_size, target_update_freq, epsilon_min, gamma, device, live_qmodel, target_qmodel, criterion, optimizer)\u001b[0m\n\u001b[0;32m    170\u001b[0m batch_done \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(batch_done, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# Forward pass through the quantum live model for Q-values\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m q_values \u001b[38;5;241m=\u001b[39m \u001b[43mlive_qmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, batch_action)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# Compute target Q-values with the target model\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 55\u001b[0m, in \u001b[0;36mHybrid_DQN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters()))\n\u001b[0;32m     53\u001b[0m theta_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_cartpole_state(x) \u001b[38;5;66;03m# Determine encoding parameter values\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m quantum_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_vals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Encode the state variables in a quantum format\u001b[39;00m\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassical_layer_1(quantum_output))\n\u001b[0;32m     58\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassical_layer_2(x))\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\qiskit_machine_learning\\connectors\\torch_connector.py:333\u001b[0m, in \u001b[0;36mTorchConnector.forward\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \n\u001b[0;32m    326\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;124;03m    Result of forward pass of this model.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    332\u001b[0m input_ \u001b[38;5;241m=\u001b[39m input_data \u001b[38;5;28;01mif\u001b[39;00m input_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTorchConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_TorchNNFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neural_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sparse\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\qiskit_machine_learning\\connectors\\torch_connector.py:100\u001b[0m, in \u001b[0;36mTorchConnector._TorchNNFunction.forward\u001b[1;34m(ctx, input_data, weights, neural_network, sparse)\u001b[0m\n\u001b[0;32m     95\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(input_data, weights)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Detach the tensors and move it to CPU as we need numpy array to compute gradients\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# of the quantum neural network. If the tensors are on CPU already this does nothing.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Some other tensors down below are also moved to CPU for computations.\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mneural_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39msparse:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m neural_network\u001b[38;5;241m.\u001b[39msparse:\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\qiskit_machine_learning\\neural_networks\\neural_network.py:228\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m    226\u001b[0m input_, shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(input_data)\n\u001b[0;32m    227\u001b[0m weights_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_weights(weights)\n\u001b[1;32m--> 228\u001b[0m output_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_forward_output(output_data, shape)\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\qiskit_machine_learning\\neural_networks\\estimator_qnn.py:224\u001b[0m, in \u001b[0;36mEstimatorQNN._forward\u001b[1;34m(self, input_data, weights)\u001b[0m\n\u001b[0;32m    218\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    219\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circuit] \u001b[38;5;241m*\u001b[39m num_samples \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    220\u001b[0m     [op \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observables \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples)],\n\u001b[0;32m    221\u001b[0m     np\u001b[38;5;241m.\u001b[39mtile(parameter_values_, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_shape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m    222\u001b[0m )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 224\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QiskitMachineLearningError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator job failed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\site-packages\\qiskit\\primitives\\primitive_job.py:51\u001b[0m, in \u001b[0;36mPrimitiveJob.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResultT:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_submitted()\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_future\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\Saad\\miniconda3\\envs\\QRL\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q = train_quantum_dqn(env, epsilon, epsilon_decay, num_episodes, replay_buffer, batch_size, target_update_freq, epsilon_min, gamma, device, live_qmodel, target_qmodel, criterion, optimizerq)\n",
    "\n",
    "#x = live_qmodel(torch.tensor([0.1,0.2,0.3,0.4]))\n",
    "filename = f\"Training/Cyclic_{os.getpid()}.txt\"\n",
    "\n",
    "np.savetxt({filename}, q, fmt='%f')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
